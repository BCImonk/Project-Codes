{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BCImonk/Project-Codes/blob/main/Skeleton_Code_for_Logistics_and_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Libraries ðŸ“•ðŸ“—ðŸ“˜"
      ],
      "metadata": {
        "id": "StvoVD5BIUS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #paths to file\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import warnings# warning filter\n",
        "#ploting libraries\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "#relevant ML libraries\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "#ML models\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#default theme\n",
        "sns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n",
        "#warning hadle\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "UFcU7zTzIUS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File path ðŸ“‚"
      ],
      "metadata": {
        "id": "WMDZp8WwIUTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list all files under the input directory\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "BdTZ9pTJIUTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path for the training set\n",
        "tr_path = #TBD Later\n",
        "#path for the testing set\n",
        "te_path = #TBD Later"
      ],
      "metadata": {
        "trusted": true,
        "id": "CfPKLyRwIUTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and Data Analysis ðŸ’»\n",
        "\n",
        "## First look at the data:\n",
        "\n",
        "Training set:"
      ],
      "metadata": {
        "id": "x5lm1UwnIUTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in csv file as a DataFrame\n",
        "tr_df = pd.read_csv(tr_path)\n",
        "# explore the first 5 rows\n",
        "tr_df.head()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ceSWwTpzIUTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing set:"
      ],
      "metadata": {
        "id": "15EtQdJIIUTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in csv file as a DataFrame\n",
        "te_df = pd.read_csv(te_path)\n",
        "# explore the first 5 rows\n",
        "te_df.head()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "NORcGf0FIUTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Size of each data set:"
      ],
      "metadata": {
        "id": "cm5waJaNIUTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"training set (row, col): {tr_df.shape}\\n\\ntesting set (row, col): {te_df.shape}\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "CNqHUk_PIUTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now the focus is shifted for the preprocessing of the training dataset."
      ],
      "metadata": {
        "id": "yu7BwKG_IUTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#column information\n",
        "tr_df.info(verbose=True, null_counts=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6q8KNWohIUTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summary statistics\n",
        "tr_df.describe()"
      ],
      "metadata": {
        "trusted": true,
        "id": "GAh_kpbmIUTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the Id column is not needed, let's drop it for both test and train datasets\n",
        "tr_df.drop('Loan_ID',axis=1,inplace=True)\n",
        "te_df.drop('Loan_ID',axis=1,inplace=True)\n",
        "#checking the new shapes\n",
        "print(f\"training set (row, col): {tr_df.shape}\\n\\ntesting set (row, col): {te_df.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "yys5FKbNIUTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing values ðŸš«"
      ],
      "metadata": {
        "id": "ntWyVpKmIUTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#missing values in decsending order\n",
        "tr_df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "r0_0x_IxIUTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the missing data\n",
        "for col in null_cols:\n",
        "    print(f\"{col}:\\n{tr_df[col].value_counts()}\\n\",\"-\"*50)\n",
        "    tr_df[col] = tr_df[col].fillna(\n",
        "    tr_df[col].dropna().mode().values[0] )   \n",
        "tr_df.isnull().sum().sort_values(ascending=False)\n",
        "print(\"After filling missing values\\n\\n\",\"#\"*50,\"\\n\")\n",
        "for col in null_cols:\n",
        "    print(f\"\\n{col}:\\n{tr_df[col].value_counts()}\\n\",\"-\"*50)"
      ],
      "metadata": {
        "trusted": true,
        "id": "LOWd6b5mIUTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visalization ðŸ“Š"
      ],
      "metadata": {
        "id": "UzULHLVrIUTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly we need to split our data to categorical and numerical data,\n",
        "\n",
        "\n",
        "using the `.select_dtypes('dtype').columns.to_list()` combination."
      ],
      "metadata": {
        "id": "tA31g2yTIUTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Region Demand distribution"
      ],
      "metadata": {
        "id": "0DVbB29HIUTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list of all the columns.columns\n",
        "#Cols = tr_df.tolist()\n",
        "#list of all the numeric columns\n",
        "num = tr_df.select_dtypes('number').columns.to_list()\n",
        "#list of all the categoric columns\n",
        "cat = tr_df.select_dtypes('object').columns.to_list()\n",
        "#numeric df\n",
        "region_num =  tr_df[num]\n",
        "#categoric df\n",
        "region_cat = tr_df[cat]"
      ],
      "metadata": {
        "trusted": true,
        "id": "CW2-mHBGIUTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tr_df[cat[-1]].value_counts())\n",
        "#tr_df[cat[-1]].hist(grid = False)\n",
        "#print(i)\n",
        "total = float(len(tr_df[cat[-1]]))\n",
        "plt.figure(figsize=(8,10))\n",
        "sns.set(style=\"whitegrid\")\n",
        "ax = sns.countplot(tr_df[cat[-1]])\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x()+p.get_width()/2.,height + 3,'{:1.2f}'.format(height/total),ha=\"center\") \n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2XThqGsAIUTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot our data\n",
        "\n",
        "Numeric:"
      ],
      "metadata": {
        "id": "OrYo0kOZIUTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in region_num:\n",
        "    plt.hist(region_num[i])\n",
        "    plt.title(i)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QLFCc-GvIUTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical (split by Region Demand):"
      ],
      "metadata": {
        "id": "pTeuSpfVIUTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cat[:-1]: \n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.subplot(2,3,1)\n",
        "    sns.countplot(x=i ,hue='Region_Status', data=tr_df ,palette='plasma')\n",
        "    plt.xlabel(i, fontsize=14)"
      ],
      "metadata": {
        "trusted": true,
        "id": "oonPKey_IUTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding data to numeric"
      ],
      "metadata": {
        "id": "ZLcKoojTIUTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the new numeric values from the to_numeric variable to both datasets\n",
        "tr_df = tr_df.applymap(lambda lable: to_numeric.get(lable) if lable in to_numeric else lable)\n",
        "te_df = te_df.applymap(lambda lable: to_numeric.get(lable) if lable in to_numeric else lable\n",
        "# checking the our manipulated dataset for validation\n",
        "print(f\"training set (row, col): {tr_df.shape}\\n\\ntesting set (row, col): {te_df.shape}\\n\")\n",
        "print(tr_df.info(), \"\\n\\n\", te_df.info())"
      ],
      "metadata": {
        "trusted": true,
        "id": "9K8fjndjIUTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation matrix "
      ],
      "metadata": {
        "id": "LxauA5M4IUTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the correlation matrix\n",
        "sns.heatmap(tr_df.corr() ,cmap='cubehelix_r')"
      ],
      "metadata": {
        "trusted": true,
        "id": "u_lfF34LIUTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation table for a more detailed analysis:"
      ],
      "metadata": {
        "id": "uEKgde93IUTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation table\n",
        "corr = tr_df.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "cSSWSGnlIUTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning models\n",
        "\n",
        "First of all we will divide our dataset into two variables `X` as the features we defined earlier and `y` as the `Region_Demand` the target value we want to predict.\n",
        "\n",
        "## Models we will use:\n",
        "\n",
        "* **Decision Tree** \n",
        "* **Random Forest**\n",
        "* **XGBoost**\n",
        "* **Logistic Regression**\n",
        "\n",
        "## The Process of Modeling the Data:\n",
        "\n",
        "1. Importing the model\n",
        "\n",
        "2. Fitting the model\n",
        "\n",
        "3. Predicting Region Demand\n",
        "\n",
        "4. Classification report by Region Demand\n",
        "\n",
        "5. Overall accuracy\n"
      ],
      "metadata": {
        "id": "z_DTdl0yIUTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = tr_df['Region Demand']\n",
        "X = tr_df.drop('Region Demand', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Guiiqz-7IUTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "![](https://i.pinimg.com/originals/eb/08/05/eb0805eb6e34bf3eac5ab4666bbcc167.gif)"
      ],
      "metadata": {
        "id": "QBc7iK-iIUTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(X_train, y_train)\n",
        "y_predict = DT.predict(X_test)\n",
        "#  prediction Summary by species\n",
        "print(classification_report(y_test, y_predict))\n",
        "# Accuracy score\n",
        "DT_SC = accuracy_score(y_predict,y_test)\n",
        "print(f\"{round(DT_SC*100,2)}% Accurate\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "k17DkumZIUTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Csv results of the test for our model:\n",
        "You can see each predition and true value side by side by the csv created in the output directory."
      ],
      "metadata": {
        "id": "tTnsfX9ZIUTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Decision_Tree=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
        "Decision_Tree.to_csv(\"Dection Tree.csv\")     "
      ],
      "metadata": {
        "trusted": true,
        "id": "IzH3yht_IUTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest\n",
        "\n",
        "![](https://miro.medium.com/max/1280/1*9kACduxnce_JdTrftM_bsA.gif)"
      ],
      "metadata": {
        "id": "w3r04oDxIUTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(X_train, y_train)\n",
        "y_predict = RF.predict(X_test)\n",
        "#  prediction Summary by species\n",
        "print(classification_report(y_test, y_predict))\n",
        "# Accuracy score\n",
        "RF_SC = accuracy_score(y_predict,y_test)\n",
        "print(f\"{round(RF_SC*100,2)}% Accurate\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "K0E8a0HLIUTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Csv results of the test for our model:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://miro.medium.com/max/900/1*a99bY1VkmfXhqW-5uAX28w.jpeg\"\n",
        "         width=\"200\" height=\"300\">\n",
        "      <tr><td align=\"center\">\n",
        "  </td></tr>\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "You can see each predition and true value side by side by the csv created in the output directory."
      ],
      "metadata": {
        "id": "ZDluCqZuIUTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Random_Forest=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
        "Random_Forest.to_csv(\"Random Forest.csv\")     "
      ],
      "metadata": {
        "trusted": true,
        "id": "eztzH3TlIUTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "![](https://f-origin.hypotheses.org/wp-content/blogs.dir/253/files/2015/06/boosting-algo-3.gif)"
      ],
      "metadata": {
        "id": "BJFqv1hvIUTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XGB = XGBClassifier()\n",
        "XGB.fit(X_train, y_train)\n",
        "y_predict = XGB.predict(X_test)\n",
        "#  prediction Summary by species\n",
        "print(classification_report(y_test, y_predict))\n",
        "# Accuracy score\n",
        "XGB_SC = accuracy_score(y_predict,y_test)\n",
        "print(f\"{round(XGB_SC*100,2)}% Accurate\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "aRrQURBJIUTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Csv results of the test for our model:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://miro.medium.com/max/900/1*a99bY1VkmfXhqW-5uAX28w.jpeg\"\n",
        "         width=\"200\" height=\"300\">\n",
        "      <tr><td align=\"center\">\n",
        "  </td></tr>\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "You can see each predition and true value side by side by the csv created in the output directory."
      ],
      "metadata": {
        "id": "mtrfPFbXIUTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XGBoost=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
        "XGBoost.to_csv(\"XGBoost.csv\")     "
      ],
      "metadata": {
        "trusted": true,
        "id": "HWALwb9FIUTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "Now, I will explore the Logistic Regression model.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://files.realpython.com/media/log-reg-2.e88a21607ba3.png\"\n",
        "          width=\"500\" height=\"400\">\n",
        "      <tr><td align=\"center\">\n",
        "  </td></tr>\n",
        "  </td></tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "8tNeY3lXIUTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegression()\n",
        "LR.fit(X_train, y_train)\n",
        "y_predict = LR.predict(X_test)\n",
        "#  prediction Summary by species\n",
        "print(classification_report(y_test, y_predict))\n",
        "# Accuracy score\n",
        "LR_SC = accuracy_score(y_predict,y_test)\n",
        "print('accuracy is',accuracy_score(y_predict,y_test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "GLj7S3CkIUTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Logistic_Regression=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\n",
        "Logistic_Regression.to_csv(\"Logistic Regression.csv\")     "
      ],
      "metadata": {
        "trusted": true,
        "id": "HYAp-DpYIUTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Csv results of the test for our model:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://miro.medium.com/max/900/1*a99bY1VkmfXhqW-5uAX28w.jpeg\"\n",
        "         width=\"200\" height=\"300\">\n",
        "      <tr><td align=\"center\">\n",
        "  </td></tr>\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "You can see each predition and true value side by side by the csv created in the output directory."
      ],
      "metadata": {
        "id": "bI1QspPRIUTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "1. `Demand History` is a very important variable  because of its high correlation with `Region Demand` therefor showind high Dependancy for the latter."
      ],
      "metadata": {
        "id": "ckkVSFXeIUTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = [DT_SC,RF_SC,XGB_SC,LR_SC]\n",
        "Models = pd.DataFrame({\n",
        "    'n_neighbors': [\"Decision Tree\",\"Random Forest\",\"XGBoost\", \"Logistic Regression\"],\n",
        "    'Score': score})\n",
        "Models.sort_values(by='Score', ascending=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mPex3YTkIUTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}